---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Jonathan Lee"
date: "4/1/2018"
output:
  html_document:
    df_print: paged
    self_contained: yes
    toc: yes
  html_notebook:
    toc: yes
---

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(broom)
library(modelr)
library(rpart)
library(partykit)
library(randomForest)
library(ROCR)
```

##Bootstrapping

###1.
```{r}
train <- read_csv("E:/Chrome Downloads/train.csv")
glimpse(train)
train$Name <- as.factor(train$Name)
train$Sex <- as.factor(train$Sex)
train$Ticket <- as.factor(train$Ticket)
train$Cabin <- as.factor(train$Cabin)
train$Embarked <- as.factor(train$Embarked)
train$Survived <- as.factor(train$Survived)
glimpse(train)
```

###2.
```{r}
titanic_boot <- bootstrap(data = train, n = 100)
is.tibble(titanic_boot)
glimpse(titanic_boot)
```

###3.
```{r}
as.tibble(titanic_boot$strap[[1]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[2]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[3]]) %>% n_distinct()
```

###4.
```{r}
age_mean <- function(input_data) {
  data <- as.tibble(input_data) # convert input data set to a tibble
  mean_age <- mean(data$Age, na.rm = TRUE) # take the mean of Age, remove NAs
  return(mean_age) # return the mean value of Age from data
}


# loop through the 100 bootstrap samples and use the age_mean()
# function
all_means <- rep(NA, 100)

# start the loop
for(i in 1:100) {
  all_means[i] <- age_mean(titanic_boot$strap[[i]])
}

# take a look at some of the means you calculated from your samples
head(all_means)

# convert to a tibble so we can use if for plotting
all_means <- tibble(all_means = all_means)
```

###5.
```{r}
ggplot(data = all_means) +
  geom_histogram(aes(x = all_means))
```

###6.
```{r}
SE_sample_mean <- sd(all_means$all_means)/sqrt(100)
SE_sample_mean
```

##Random Forest

###1.
```{r}
set.seed(987)

model_data <- resample_partition(train, c(test = 0.3, train = 0.7))
train_set <- as.tibble(model_data$train)
test_set <- as.tibble(model_data$test)
```

###2.
I've noticed that there are a lot more branches, which is understandable since it has more variables. It also doesn't have some of the variables in the tree. SibSp, Parch, and Embarked are not in the tree.
```{r}
tree_mod <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train_set)
plot(as.party(tree_mod))
```

###3.
```{r}
rf_mod <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
                         data = train_set, 
                         ntrees = 500, 
                         mtry = 4, 
                         na.action = na.roughfix)
```

###4.

The question for 4. is asking to compare the two models, but when comparing I believe we usually use the ROC plot which is done in question 5, and then question 6 asks for the comparison again, so I will answer it in question 6.
```{r}
rf_preds <- predict(rf_mod, newdata = test_set, type = 'prob')[,2]
tree_preds <- predict(tree_mod, newdata = test_set)[,2]

pred_rf <- prediction(predictions = rf_preds, labels = test_set$Survived)
pred_tree <- prediction(predictions = tree_preds, labels = test_set$Survived)
```

###5.

```{r}
# get the FPR and TPR for the logistic model
# recall that the ROC curve plots the FPR on the x-axis
perf_rf <- performance(pred_rf, measure = 'tpr', x.measure = 'fpr')
perf_rf_tbl <- tibble(perf_rf@x.values[[1]], perf_rf@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_rf_tbl) <- c('fpr', 'tpr')

# get the FPR and TPR for the tree model
perf_tree <- performance(pred_tree, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl <- tibble(perf_tree@x.values[[1]], perf_tree@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_tree_tbl) <- c('fpr', 'tpr')

# Plotting function for plotting a nice ROC curve using ggplot
plot_roc <- function(perf_tbl) {
  p <- ggplot(data = perf_tbl) + 
  geom_line(mapping = aes(x = fpr, y = tpr, color = list_class)) +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  labs(x = 'False positive rate', y = 'True positive rate') +
  theme_bw()
  return(p)
}

##we'll need to create a new tibble
list_class <- c(rep("rf", length(perf_rf_tbl$fpr)), rep("tree", length(perf_tree_tbl$fpr)))
combined_tibble <- bind_rows(perf_rf_tbl, perf_tree_tbl)
combined_tibble$list_class <- list_class

plot_roc(combined_tibble)
```

###6.

To compare, we'll need to get the AUC values. As you can see the AUC value for the random forest is higher, so I would say the random forest performs better.

The approximate fpr at .75 tpr for random forest is approximately .15 and for the decision tree it is .35
```{r}
# calculate the AUC
auc_rf <- performance(pred_rf, measure = 'auc')
auc_tree <- performance(pred_tree, measure = 'auc')

# extract the AUC value
auc_rf@y.values[[1]]
auc_tree@y.values[[1]]
```


